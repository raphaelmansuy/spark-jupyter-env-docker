{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b58a17b-3b47-4ccd-b1e7-2474e49caf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                 \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  ;\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.postgresql:postgresql:42.3.6`\n",
    "\n",
    "import $ivy.`org.apache.spark::spark-sql:3.0.0`;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d322953-2346-4772-bab6-8ebe23bcdca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "22/06/10 06:29:23 INFO SparkContext: Running Spark version 3.0.0\n",
      "22/06/10 06:29:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/10 06:29:24 INFO ResourceUtils: ==============================================================\n",
      "22/06/10 06:29:24 INFO ResourceUtils: Resources for spark.driver:\n",
      "\n",
      "22/06/10 06:29:24 INFO ResourceUtils: ==============================================================\n",
      "22/06/10 06:29:24 INFO SparkContext: Submitted application: scala-spark-notebook\n",
      "22/06/10 06:29:24 INFO SecurityManager: Changing view acls to: root\n",
      "22/06/10 06:29:24 INFO SecurityManager: Changing modify acls to: root\n",
      "22/06/10 06:29:24 INFO SecurityManager: Changing view acls groups to: \n",
      "22/06/10 06:29:24 INFO SecurityManager: Changing modify acls groups to: \n",
      "22/06/10 06:29:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "22/06/10 06:29:24 INFO Utils: Successfully started service 'sparkDriver' on port 40789.\n",
      "22/06/10 06:29:24 INFO SparkEnv: Registering MapOutputTracker\n",
      "22/06/10 06:29:24 INFO SparkEnv: Registering BlockManagerMaster\n",
      "22/06/10 06:29:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "22/06/10 06:29:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "22/06/10 06:29:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/06/10 06:29:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-683cb399-dd5d-4f49-8143-5ea514b4362e\n",
      "22/06/10 06:29:24 INFO MemoryStore: MemoryStore started with capacity 1111.8 MiB\n",
      "22/06/10 06:29:24 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "22/06/10 06:29:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "22/06/10 06:29:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://ecf4d78a32fa:4040\n",
      "22/06/10 06:29:24 INFO SparkContext: Added JAR ../jars/postgresql-42.3.6.jar at spark://ecf4d78a32fa:40789/jars/postgresql-42.3.6.jar with timestamp 1654842564686\n",
      "22/06/10 06:29:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...\n",
      "22/06/10 06:29:24 INFO TransportClientFactory: Successfully created connection to spark-master/192.168.32.4:7077 after 25 ms (0 ms spent in bootstraps)\n",
      "22/06/10 06:29:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220610062924-0006\n",
      "22/06/10 06:29:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220610062924-0006/0 on worker-20220610061512-192.168.32.9-45101 (192.168.32.9:45101) with 1 core(s)\n",
      "22/06/10 06:29:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20220610062924-0006/0 on hostPort 192.168.32.9:45101 with 1 core(s), 512.0 MiB RAM\n",
      "22/06/10 06:29:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220610062924-0006/1 on worker-20220610061512-192.168.32.8-35839 (192.168.32.8:35839) with 1 core(s)\n",
      "22/06/10 06:29:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20220610062924-0006/1 on hostPort 192.168.32.8:35839 with 1 core(s), 512.0 MiB RAM\n",
      "22/06/10 06:29:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36531.\n",
      "22/06/10 06:29:25 INFO NettyBlockTransferService: Server created on ecf4d78a32fa:36531\n",
      "22/06/10 06:29:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "22/06/10 06:29:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ecf4d78a32fa, 36531, None)\n",
      "22/06/10 06:29:25 INFO BlockManagerMasterEndpoint: Registering block manager ecf4d78a32fa:36531 with 1111.8 MiB RAM, BlockManagerId(driver, ecf4d78a32fa, 36531, None)\n",
      "22/06/10 06:29:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ecf4d78a32fa, 36531, None)\n",
      "22/06/10 06:29:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ecf4d78a32fa, 36531, None)\n",
      "22/06/10 06:29:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220610062924-0006/1 is now RUNNING\n",
      "22/06/10 06:29:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220610062924-0006/0 is now RUNNING\n",
      "22/06/10 06:29:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@69830203\n",
       "\u001b[36mres1_2\u001b[39m: \u001b[32mClass\u001b[39m[\u001b[32m?0\u001b[39m] = class org.postgresql.Driver\n",
       "\u001b[36mjdbcHostname\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"postgres\"\u001b[39m\n",
       "\u001b[36mjdbcPort\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m5432\u001b[39m\n",
       "\u001b[36mjdbcDatabase\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"postgres\"\u001b[39m\n",
       "\u001b[36mjdbcUsername\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"postgres\"\u001b[39m\n",
       "\u001b[36mjdbcPassword\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"postgres\"\u001b[39m\n",
       "\u001b[36mjdbcUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"jdbc:postgresql://postgres:5432/postgres\"\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Properties\n",
       "\u001b[39m\n",
       "\u001b[36mconnectionProperties\u001b[39m: \u001b[32mProperties\u001b[39m = {user=postgres, password=postgres, driver=org.postgresql.Driver}\n",
       "\u001b[36mres1_11\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mres1_12\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mres1_13\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.sql.DriverManager\n",
       "\u001b[39m\n",
       "\u001b[36mconnection\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mConnection\u001b[39m = org.postgresql.jdbc.PgConnection@5b726fc2\n",
       "\u001b[36mres1_16\u001b[39m: \u001b[32mBoolean\u001b[39m = false"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = SparkSession.\n",
    "            builder().\n",
    "            appName(\"scala-spark-notebook\").\n",
    "            master(\"spark://spark-master:7077\").\n",
    "            config(\"spark.jars\", \"../jars/postgresql-42.3.6.jar\").\n",
    "            config(\"spark.executor.memory\", \"512m\").\n",
    "            getOrCreate()\n",
    "\n",
    "Class.forName(\"org.postgresql.Driver\")\n",
    "\n",
    "\n",
    "val jdbcHostname = \"postgres\"\n",
    "val jdbcPort = 5432\n",
    "val jdbcDatabase = \"postgres\"\n",
    "val jdbcUsername = \"postgres\"\n",
    "val jdbcPassword = \"postgres\"\n",
    "\n",
    "// Create the JDBC URL without passing in the user and password parameters.\n",
    "val jdbcUrl = s\"jdbc:postgresql://${jdbcHostname}:${jdbcPort}/${jdbcDatabase}\"\n",
    "\n",
    "// Create a Properties() object to hold the parameters.\n",
    "import java.util.Properties\n",
    "val connectionProperties = new Properties()\n",
    "\n",
    "connectionProperties.put(\"user\", s\"${jdbcUsername}\")\n",
    "connectionProperties.put(\"password\", s\"${jdbcPassword}\")\n",
    "connectionProperties.put(\"driver\",\"org.postgresql.Driver\")\n",
    "\n",
    "import java.sql.DriverManager\n",
    "val connection = DriverManager.getConnection(jdbcUrl, jdbcUsername, jdbcPassword)\n",
    "connection.isClosed()            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7436a8ed-3788-42f0-bdb8-6019fce011e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/10 06:29:26 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/workspace/demo/spark-warehouse').\n",
      "22/06/10 06:29:26 INFO SharedState: Warehouse path is 'file:/opt/workspace/demo/spark-warehouse'.\n",
      "22/06/10 06:29:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 512, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "22/06/10 06:29:26 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.32.8:58206) with ID 1\n",
      "22/06/10 06:29:26 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.32.9:38788) with ID 0\n",
      "22/06/10 06:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.32.8:37127 with 93.3 MiB RAM, BlockManagerId(1, 192.168.32.8, 37127, None)\n",
      "22/06/10 06:29:27 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.32.9:41811 with 93.3 MiB RAM, BlockManagerId(0, 192.168.32.9, 41811, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [customerid: int, firstname: string ... 18 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = \n",
    "  spark\n",
    "    .read\n",
    "    .jdbc(jdbcUrl,\n",
    "         \"customers\", \n",
    "         connectionProperties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0b131d-6bfe-4e9d-abc9-680db081dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/10 06:29:28 INFO CodeGenerator: Code generated in 122.348959 ms\n",
      "22/06/10 06:29:28 INFO SparkContext: Starting job: show at cmd3.sc:1\n",
      "22/06/10 06:29:28 INFO DAGScheduler: Got job 0 (show at cmd3.sc:1) with 1 output partitions\n",
      "22/06/10 06:29:28 INFO DAGScheduler: Final stage: ResultStage 0 (show at cmd3.sc:1)\n",
      "22/06/10 06:29:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/06/10 06:29:28 INFO DAGScheduler: Missing parents: List()\n",
      "22/06/10 06:29:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at show at cmd3.sc:1), which has no missing parents\n",
      "22/06/10 06:29:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.3 KiB, free 1111.8 MiB)\n",
      "22/06/10 06:29:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 1111.8 MiB)\n",
      "22/06/10 06:29:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ecf4d78a32fa:36531 (size: 6.2 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200\n",
      "22/06/10 06:29:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at cmd3.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "22/06/10 06:29:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks\n",
      "22/06/10 06:29:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.32.8, executor 1, partition 0, PROCESS_LOCAL, 7175 bytes)\n",
      "22/06/10 06:29:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.32.8:37127 (size: 6.2 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1025 ms on 192.168.32.8 (executor 1) (1/1)\n",
      "22/06/10 06:29:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "22/06/10 06:29:29 INFO DAGScheduler: ResultStage 0 (show at cmd3.sc:1) finished in 1.169 s\n",
      "22/06/10 06:29:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/06/10 06:29:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "22/06/10 06:29:29 INFO DAGScheduler: Job 0 finished: show at cmd3.sc:1, took 1.214374 s\n",
      "22/06/10 06:29:29 INFO CodeGenerator: Code generated in 39.142625 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+-------------------+--------+-------+-----+-----+-------+------+-------------------+----------+--------------+----------------+--------------------+--------+--------+---+------+------+\n",
      "|customerid|firstname|  lastname|           address1|address2|   city|state|  zip|country|region|              email|     phone|creditcardtype|      creditcard|creditcardexpiration|username|password|age|income|gender|\n",
      "+----------+---------+----------+-------------------+--------+-------+-----+-----+-------+------+-------------------+----------+--------------+----------------+--------------------+--------+--------+---+------+------+\n",
      "|         1|   VKUUXF|ITHOMQJNYX|4608499546 Dell Way|    null|QSDPAGD|   SD|24101|     US|     1|ITHOMQJNYX@dell.com|4608499546|             1|1979279217775911|             2012/03|   user1|password| 55|100000|     M|\n",
      "|         2|   HQNMZH|UNUKXHJVXB|5119315633 Dell Way|    null|YNCERXJ|   AZ|11802|     US|     1|UNUKXHJVXB@dell.com|5119315633|             1|3144519586581737|             2012/11|   user2|password| 80| 40000|     M|\n",
      "|         3|   JTNRNB|LYYSHTQJRE|6297761196 Dell Way|    null|LWVIFXJ|   OH|96082|     US|     1|LYYSHTQJRE@dell.com|6297761196|             4|8728086929768325|             2010/12|   user3|password| 47|100000|     M|\n",
      "|         4|   XMFYXD|WQLQHUHLFE|9862764981 Dell Way|    null|HOKEXCD|   MS|78442|     US|     1|WQLQHUHLFE@dell.com|9862764981|             5|7160005148965866|             2009/09|   user4|password| 44| 40000|     F|\n",
      "|         5|   PGDTDU|ETBYBNEGUT|2841895775 Dell Way|    null|RZQTCDN|   AZ|16291|     US|     1|ETBYBNEGUT@dell.com|2841895775|             3|8377095518168063|             2010/10|   user5|password| 21| 20000|     M|\n",
      "|         6|   FXDZBW|BAXPEEKXVJ|6192740010 Dell Way|    null|OPLRCNT|   IN|99300|     US|     1|BAXPEEKXVJ@dell.com|6192740010|             5|7730283664073796|             2011/01|   user6|password| 72|100000|     M|\n",
      "|         7|   WVZTXZ|RMEVXCQGQF|9743191382 Dell Way|    null|SIIGBQF|   NV|55961|     US|     1|RMEVXCQGQF@dell.com|9743191382|             2|5914961899630726|             2011/02|   user7|password| 52| 60000|     M|\n",
      "|         8|   LIWLAI|PVGRMMHSEQ|7576564107 Dell Way|    null|BKSRQJE|   NJ|66444|     US|     1|PVGRMMHSEQ@dell.com|7576564107|             2|7663945967331529|             2009/12|   user8|password| 67| 80000|     F|\n",
      "|         9|   NCGWRC|CJOPRHUHIE|7291678624 Dell Way|    null|ZAVIELY|   VT|78838|     US|     1|CJOPRHUHIE@dell.com|7291678624|             1|7172072122339160|             2009/10|   user9|password| 86|100000|     M|\n",
      "|        10|   FUOHXX|WMOEHWMMWM|2603867587 Dell Way|    null|HERSDPM|   TN|75182|     US|     1|WMOEHWMMWM@dell.com|2603867587|             2|5486729339230806|             2008/02|  user10|password| 44| 40000|     M|\n",
      "|        11|   XQVVMI|KRPGDBCQJH|2415449050 Dell Way|    null|ICLYPGR|   PA|53868|     US|     1|KRPGDBCQJH@dell.com|2415449050|             5|6630987872369588|             2010/03|  user11|password| 58| 60000|     M|\n",
      "|        12|   KGISQZ|IXDKAUUHCW|1896033667 Dell Way|    null|SBLZSFM|   UT|18452|     US|     1|IXDKAUUHCW@dell.com|1896033667|             2|3715867913328111|             2011/10|  user12|password| 27| 20000|     F|\n",
      "|        13|   LURLDP|PNPJHXMEPN|3029418206 Dell Way|    null|QPGVBCY|   DE|53356|     US|     1|PNPJHXMEPN@dell.com|3029418206|             5|3617457962129265|             2009/11|  user13|password| 43|100000|     M|\n",
      "|        14|   AGUQVI|FFPCRUSFKI|3748672054 Dell Way|    null|LGKNEOA|   MA|44395|     US|     1|FFPCRUSFKI@dell.com|3748672054|             4|3344003576319665|             2011/07|  user14|password| 85| 80000|     M|\n",
      "|        15|   SIQANV|QQNKJSURDA|3354132892 Dell Way|    null|BREQSOA|   AK|37471|     US|     1|QQNKJSURDA@dell.com|3354132892|             4|8717996907886119|             2008/05|  user15|password| 66|100000|     M|\n",
      "|        16|   IXEENV|RXEKSWOTYG|6914808178 Dell Way|    null|YOYMOYU|   SD|63504|     US|     1|RXEKSWOTYG@dell.com|6914808178|             5|9422665674239398|             2009/11|  user16|password| 61| 80000|     M|\n",
      "|        17|   UUGPME|UWWRKPPQOD|1436497137 Dell Way|    null|PASNVNC|   MO|55931|     US|     1|UWWRKPPQOD@dell.com|1436497137|             5|4461925670970231|             2011/06|  user17|password| 28| 60000|     F|\n",
      "|        18|   KASOVP|LMZBBQPFFQ|4002123087 Dell Way|    null|YTMLWYY|   VA|79031|     US|     1|LMZBBQPFFQ@dell.com|4002123087|             3|2972224516794085|             2010/12|  user18|password| 52|100000|     M|\n",
      "|        19|   ELUTXG|TZIKOOQEMJ|6334227072 Dell Way|    null|RXFPWCJ|   GA|68186|     US|     1|TZIKOOQEMJ@dell.com|6334227072|             4|6367064577993006|             2008/07|  user19|password| 59| 40000|     F|\n",
      "|        20|   IAYPUX|YELMUQZEHW|7467996902 Dell Way|    null|JXTMHYD|   UT|66087|     US|     1|YELMUQZEHW@dell.com|7467996902|             5|2656596019398421|             2009/03|  user20|password| 32| 80000|     F|\n",
      "+----------+---------+----------+-------------------+--------+-------+-----+-----+-------+------+-------------------+----------+--------------+----------------+--------------------+--------+--------+---+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3834487c-fd93-4945-97b7-91d3ac66a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/10 06:29:30 INFO CodeGenerator: Code generated in 7.793792 ms\n",
      "22/06/10 06:29:30 INFO CodeGenerator: Code generated in 6.784541 ms\n",
      "22/06/10 06:29:30 INFO SparkContext: Starting job: count at cmd4.sc:1\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Registering RDD 5 (count at cmd4.sc:1) as input to shuffle 0\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Got job 1 (count at cmd4.sc:1) with 1 output partitions\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Final stage: ResultStage 2 (count at cmd4.sc:1)\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at cmd4.sc:1), which has no missing parents\n",
      "22/06/10 06:29:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.9 KiB, free 1111.8 MiB)\n",
      "22/06/10 06:29:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 1111.8 MiB)\n",
      "22/06/10 06:29:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ecf4d78a32fa:36531 (size: 6.2 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at cmd4.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "22/06/10 06:29:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks\n",
      "22/06/10 06:29:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.32.9, executor 0, partition 0, PROCESS_LOCAL, 7164 bytes)\n",
      "22/06/10 06:29:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.32.9:41811 (size: 6.2 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 816 ms on 192.168.32.9 (executor 0) (1/1)\n",
      "22/06/10 06:29:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "22/06/10 06:29:30 INFO DAGScheduler: ShuffleMapStage 1 (count at cmd4.sc:1) finished in 0.836 s\n",
      "22/06/10 06:29:30 INFO DAGScheduler: looking for newly runnable stages\n",
      "22/06/10 06:29:30 INFO DAGScheduler: running: Set()\n",
      "22/06/10 06:29:30 INFO DAGScheduler: waiting: Set(ResultStage 2)\n",
      "22/06/10 06:29:30 INFO DAGScheduler: failed: Set()\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[8] at count at cmd4.sc:1), which has no missing parents\n",
      "22/06/10 06:29:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 1111.8 MiB)\n",
      "22/06/10 06:29:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 1111.7 MiB)\n",
      "22/06/10 06:29:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ecf4d78a32fa:36531 (size: 5.0 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200\n",
      "22/06/10 06:29:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at count at cmd4.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "22/06/10 06:29:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks\n",
      "22/06/10 06:29:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 192.168.32.9, executor 0, partition 0, NODE_LOCAL, 7329 bytes)\n",
      "22/06/10 06:29:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.32.9:41811 (size: 5.0 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.32.9:38788\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 145 ms on 192.168.32.9 (executor 0) (1/1)\n",
      "22/06/10 06:29:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "22/06/10 06:29:31 INFO DAGScheduler: ResultStage 2 (count at cmd4.sc:1) finished in 0.159 s\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/06/10 06:29:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Job 1 finished: count at cmd4.sc:1, took 1.019816 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres4\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m20000L\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33c72b7-28a5-4d33-939b-356c464b58e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [customerid: int, firstname: string ... 1 more field]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = \n",
    "  spark\n",
    "    .read\n",
    "    .jdbc(jdbcUrl,\n",
    "         \"(select customerid,firstname,lastname from customers) as T\", \n",
    "         connectionProperties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b5d3f2-006f-462b-a5e1-c46431dfad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/10 06:29:31 INFO JDBCRelation: Number of partitions: 200, WHERE clauses of these partitions: \"customerid\" < 110 or \"customerid\" is null, \"customerid\" >= 110 AND \"customerid\" < 120, \"customerid\" >= 120 AND \"customerid\" < 130, \"customerid\" >= 130 AND \"customerid\" < 140, \"customerid\" >= 140 AND \"customerid\" < 150, \"customerid\" >= 150 AND \"customerid\" < 160, \"customerid\" >= 160 AND \"customerid\" < 170, \"customerid\" >= 170 AND \"customerid\" < 180, \"customerid\" >= 180 AND \"customerid\" < 190, \"customerid\" >= 190 AND \"customerid\" < 200, \"customerid\" >= 200 AND \"customerid\" < 210, \"customerid\" >= 210 AND \"customerid\" < 220, \"customerid\" >= 220 AND \"customerid\" < 230, \"customerid\" >= 230 AND \"customerid\" < 240, \"customerid\" >= 240 AND \"customerid\" < 250, \"customerid\" >= 250 AND \"customerid\" < 260, \"customerid\" >= 260 AND \"customerid\" < 270, \"customerid\" >= 270 AND \"customerid\" < 280, \"customerid\" >= 280 AND \"customerid\" < 290, \"customerid\" >= 290 AND \"customerid\" < 300, \"customerid\" >= 300 AND \"customerid\" < 310, \"customerid\" >= 310 AND \"customerid\" < 320, \"customerid\" >= 320 AND \"customerid\" < 330, \"customerid\" >= 330 AND \"customerid\" < 340, \"customerid\" >= 340 AND \"customerid\" < 350, \"customerid\" >= 350 AND \"customerid\" < 360, \"customerid\" >= 360 AND \"customerid\" < 370, \"customerid\" >= 370 AND \"customerid\" < 380, \"customerid\" >= 380 AND \"customerid\" < 390, \"customerid\" >= 390 AND \"customerid\" < 400, \"customerid\" >= 400 AND \"customerid\" < 410, \"customerid\" >= 410 AND \"customerid\" < 420, \"customerid\" >= 420 AND \"customerid\" < 430, \"customerid\" >= 430 AND \"customerid\" < 440, \"customerid\" >= 440 AND \"customerid\" < 450, \"customerid\" >= 450 AND \"customerid\" < 460, \"customerid\" >= 460 AND \"customerid\" < 470, \"customerid\" >= 470 AND \"customerid\" < 480, \"customerid\" >= 480 AND \"customerid\" < 490, \"customerid\" >= 490 AND \"customerid\" < 500, \"customerid\" >= 500 AND \"customerid\" < 510, \"customerid\" >= 510 AND \"customerid\" < 520, \"customerid\" >= 520 AND \"customerid\" < 530, \"customerid\" >= 530 AND \"customerid\" < 540, \"customerid\" >= 540 AND \"customerid\" < 550, \"customerid\" >= 550 AND \"customerid\" < 560, \"customerid\" >= 560 AND \"customerid\" < 570, \"customerid\" >= 570 AND \"customerid\" < 580, \"customerid\" >= 580 AND \"customerid\" < 590, \"customerid\" >= 590 AND \"customerid\" < 600, \"customerid\" >= 600 AND \"customerid\" < 610, \"customerid\" >= 610 AND \"customerid\" < 620, \"customerid\" >= 620 AND \"customerid\" < 630, \"customerid\" >= 630 AND \"customerid\" < 640, \"customerid\" >= 640 AND \"customerid\" < 650, \"customerid\" >= 650 AND \"customerid\" < 660, \"customerid\" >= 660 AND \"customerid\" < 670, \"customerid\" >= 670 AND \"customerid\" < 680, \"customerid\" >= 680 AND \"customerid\" < 690, \"customerid\" >= 690 AND \"customerid\" < 700, \"customerid\" >= 700 AND \"customerid\" < 710, \"customerid\" >= 710 AND \"customerid\" < 720, \"customerid\" >= 720 AND \"customerid\" < 730, \"customerid\" >= 730 AND \"customerid\" < 740, \"customerid\" >= 740 AND \"customerid\" < 750, \"customerid\" >= 750 AND \"customerid\" < 760, \"customerid\" >= 760 AND \"customerid\" < 770, \"customerid\" >= 770 AND \"customerid\" < 780, \"customerid\" >= 780 AND \"customerid\" < 790, \"customerid\" >= 790 AND \"customerid\" < 800, \"customerid\" >= 800 AND \"customerid\" < 810, \"customerid\" >= 810 AND \"customerid\" < 820, \"customerid\" >= 820 AND \"customerid\" < 830, \"customerid\" >= 830 AND \"customerid\" < 840, \"customerid\" >= 840 AND \"customerid\" < 850, \"customerid\" >= 850 AND \"customerid\" < 860, \"customerid\" >= 860 AND \"customerid\" < 870, \"customerid\" >= 870 AND \"customerid\" < 880, \"customerid\" >= 880 AND \"customerid\" < 890, \"customerid\" >= 890 AND \"customerid\" < 900, \"customerid\" >= 900 AND \"customerid\" < 910, \"customerid\" >= 910 AND \"customerid\" < 920, \"customerid\" >= 920 AND \"customerid\" < 930, \"customerid\" >= 930 AND \"customerid\" < 940, \"customerid\" >= 940 AND \"customerid\" < 950, \"customerid\" >= 950 AND \"customerid\" < 960, \"customerid\" >= 960 AND \"customerid\" < 970, \"customerid\" >= 970 AND \"customerid\" < 980, \"customerid\" >= 980 AND \"customerid\" < 990, \"customerid\" >= 990 AND \"customerid\" < 1000, \"customerid\" >= 1000 AND \"customerid\" < 1010, \"customerid\" >= 1010 AND \"customerid\" < 1020, \"customerid\" >= 1020 AND \"customerid\" < 1030, \"customerid\" >= 1030 AND \"customerid\" < 1040, \"customerid\" >= 1040 AND \"customerid\" < 1050, \"customerid\" >= 1050 AND \"customerid\" < 1060, \"customerid\" >= 1060 AND \"customerid\" < 1070, \"customerid\" >= 1070 AND \"customerid\" < 1080, \"customerid\" >= 1080 AND \"customerid\" < 1090, \"customerid\" >= 1090 AND \"customerid\" < 1100, \"customerid\" >= 1100 AND \"customerid\" < 1110, \"customerid\" >= 1110 AND \"customerid\" < 1120, \"customerid\" >= 1120 AND \"customerid\" < 1130, \"customerid\" >= 1130 AND \"customerid\" < 1140, \"customerid\" >= 1140 AND \"customerid\" < 1150, \"customerid\" >= 1150 AND \"customerid\" < 1160, \"customerid\" >= 1160 AND \"customerid\" < 1170, \"customerid\" >= 1170 AND \"customerid\" < 1180, \"customerid\" >= 1180 AND \"customerid\" < 1190, \"customerid\" >= 1190 AND \"customerid\" < 1200, \"customerid\" >= 1200 AND \"customerid\" < 1210, \"customerid\" >= 1210 AND \"customerid\" < 1220, \"customerid\" >= 1220 AND \"customerid\" < 1230, \"customerid\" >= 1230 AND \"customerid\" < 1240, \"customerid\" >= 1240 AND \"customerid\" < 1250, \"customerid\" >= 1250 AND \"customerid\" < 1260, \"customerid\" >= 1260 AND \"customerid\" < 1270, \"customerid\" >= 1270 AND \"customerid\" < 1280, \"customerid\" >= 1280 AND \"customerid\" < 1290, \"customerid\" >= 1290 AND \"customerid\" < 1300, \"customerid\" >= 1300 AND \"customerid\" < 1310, \"customerid\" >= 1310 AND \"customerid\" < 1320, \"customerid\" >= 1320 AND \"customerid\" < 1330, \"customerid\" >= 1330 AND \"customerid\" < 1340, \"customerid\" >= 1340 AND \"customerid\" < 1350, \"customerid\" >= 1350 AND \"customerid\" < 1360, \"customerid\" >= 1360 AND \"customerid\" < 1370, \"customerid\" >= 1370 AND \"customerid\" < 1380, \"customerid\" >= 1380 AND \"customerid\" < 1390, \"customerid\" >= 1390 AND \"customerid\" < 1400, \"customerid\" >= 1400 AND \"customerid\" < 1410, \"customerid\" >= 1410 AND \"customerid\" < 1420, \"customerid\" >= 1420 AND \"customerid\" < 1430, \"customerid\" >= 1430 AND \"customerid\" < 1440, \"customerid\" >= 1440 AND \"customerid\" < 1450, \"customerid\" >= 1450 AND \"customerid\" < 1460, \"customerid\" >= 1460 AND \"customerid\" < 1470, \"customerid\" >= 1470 AND \"customerid\" < 1480, \"customerid\" >= 1480 AND \"customerid\" < 1490, \"customerid\" >= 1490 AND \"customerid\" < 1500, \"customerid\" >= 1500 AND \"customerid\" < 1510, \"customerid\" >= 1510 AND \"customerid\" < 1520, \"customerid\" >= 1520 AND \"customerid\" < 1530, \"customerid\" >= 1530 AND \"customerid\" < 1540, \"customerid\" >= 1540 AND \"customerid\" < 1550, \"customerid\" >= 1550 AND \"customerid\" < 1560, \"customerid\" >= 1560 AND \"customerid\" < 1570, \"customerid\" >= 1570 AND \"customerid\" < 1580, \"customerid\" >= 1580 AND \"customerid\" < 1590, \"customerid\" >= 1590 AND \"customerid\" < 1600, \"customerid\" >= 1600 AND \"customerid\" < 1610, \"customerid\" >= 1610 AND \"customerid\" < 1620, \"customerid\" >= 1620 AND \"customerid\" < 1630, \"customerid\" >= 1630 AND \"customerid\" < 1640, \"customerid\" >= 1640 AND \"customerid\" < 1650, \"customerid\" >= 1650 AND \"customerid\" < 1660, \"customerid\" >= 1660 AND \"customerid\" < 1670, \"customerid\" >= 1670 AND \"customerid\" < 1680, \"customerid\" >= 1680 AND \"customerid\" < 1690, \"customerid\" >= 1690 AND \"customerid\" < 1700, \"customerid\" >= 1700 AND \"customerid\" < 1710, \"customerid\" >= 1710 AND \"customerid\" < 1720, \"customerid\" >= 1720 AND \"customerid\" < 1730, \"customerid\" >= 1730 AND \"customerid\" < 1740, \"customerid\" >= 1740 AND \"customerid\" < 1750, \"customerid\" >= 1750 AND \"customerid\" < 1760, \"customerid\" >= 1760 AND \"customerid\" < 1770, \"customerid\" >= 1770 AND \"customerid\" < 1780, \"customerid\" >= 1780 AND \"customerid\" < 1790, \"customerid\" >= 1790 AND \"customerid\" < 1800, \"customerid\" >= 1800 AND \"customerid\" < 1810, \"customerid\" >= 1810 AND \"customerid\" < 1820, \"customerid\" >= 1820 AND \"customerid\" < 1830, \"customerid\" >= 1830 AND \"customerid\" < 1840, \"customerid\" >= 1840 AND \"customerid\" < 1850, \"customerid\" >= 1850 AND \"customerid\" < 1860, \"customerid\" >= 1860 AND \"customerid\" < 1870, \"customerid\" >= 1870 AND \"customerid\" < 1880, \"customerid\" >= 1880 AND \"customerid\" < 1890, \"customerid\" >= 1890 AND \"customerid\" < 1900, \"customerid\" >= 1900 AND \"customerid\" < 1910, \"customerid\" >= 1910 AND \"customerid\" < 1920, \"customerid\" >= 1920 AND \"customerid\" < 1930, \"customerid\" >= 1930 AND \"customerid\" < 1940, \"customerid\" >= 1940 AND \"customerid\" < 1950, \"customerid\" >= 1950 AND \"customerid\" < 1960, \"customerid\" >= 1960 AND \"customerid\" < 1970, \"customerid\" >= 1970 AND \"customerid\" < 1980, \"customerid\" >= 1980 AND \"customerid\" < 1990, \"customerid\" >= 1990 AND \"customerid\" < 2000, \"customerid\" >= 2000 AND \"customerid\" < 2010, \"customerid\" >= 2010 AND \"customerid\" < 2020, \"customerid\" >= 2020 AND \"customerid\" < 2030, \"customerid\" >= 2030 AND \"customerid\" < 2040, \"customerid\" >= 2040 AND \"customerid\" < 2050, \"customerid\" >= 2050 AND \"customerid\" < 2060, \"customerid\" >= 2060 AND \"customerid\" < 2070, \"customerid\" >= 2070 AND \"customerid\" < 2080, \"customerid\" >= 2080 AND \"customerid\" < 2090, \"customerid\" >= 2090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mqueryOpts\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m\"lowerBound\"\u001b[39m -> \u001b[32m\"100\"\u001b[39m,\n",
       "  \u001b[32m\"url\"\u001b[39m -> \u001b[32m\"jdbc:postgresql://postgres:5432/postgres\"\u001b[39m,\n",
       "  \u001b[32m\"partitionColumn\"\u001b[39m -> \u001b[32m\"customerid\"\u001b[39m,\n",
       "  \u001b[32m\"upperBound\"\u001b[39m -> \u001b[32m\"2000\"\u001b[39m,\n",
       "  \u001b[32m\"dbtable\"\u001b[39m -> \u001b[32m\"(select customerid,firstname,lastname from customers where customerid > 100) as T\"\u001b[39m,\n",
       "  \u001b[32m\"user\"\u001b[39m -> \u001b[32m\"postgres\"\u001b[39m,\n",
       "  \u001b[32m\"numPartitions\"\u001b[39m -> \u001b[32m\"200\"\u001b[39m,\n",
       "  \u001b[32m\"password\"\u001b[39m -> \u001b[32m\"postgres\"\u001b[39m\n",
       ")\n",
       "\u001b[36mdf2\u001b[39m: \u001b[32mDataFrame\u001b[39m = [customerid: int, firstname: string ... 1 more field]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val queryOpts = Map(\"dbtable\"->\"(select customerid,firstname,lastname from customers where customerid > 100) as T\",\"lowerBound\"->\"100\",\"upperBound\"->\"2000\",\"partitionColumn\"->\"customerid\",\"numPartitions\"->\"200\",\"url\"->jdbcUrl,\"user\"->jdbcUsername,\"password\"->jdbcPassword) \n",
    "val df2 =  spark.read.format(\"jdbc\").options(queryOpts).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aed9092-f048-4f3f-ab61-e845411c224b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/10 06:29:31 INFO CodeGenerator: Code generated in 8.777125 ms\n",
      "22/06/10 06:29:31 INFO SparkContext: Starting job: head at cmd7.sc:1\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Got job 2 (head at cmd7.sc:1) with 1 output partitions\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Final stage: ResultStage 3 (head at cmd7.sc:1)\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Missing parents: List()\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at head at cmd7.sc:1), which has no missing parents\n",
      "22/06/10 06:29:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 20.3 KiB, free 1111.7 MiB)\n",
      "22/06/10 06:29:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 1111.7 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ecf4d78a32fa:36531 (size: 7.3 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at head at cmd7.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "22/06/10 06:29:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 192.168.32.9, executor 0, partition 0, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.32.9:41811 in memory (size: 5.0 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ecf4d78a32fa:36531 in memory (size: 5.0 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.32.9:41811 (size: 7.3 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ecf4d78a32fa:36531 in memory (size: 6.2 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.32.8:37127 in memory (size: 6.2 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ecf4d78a32fa:36531 in memory (size: 6.2 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 92 ms on 192.168.32.9 (executor 0) (1/1)\n",
      "22/06/10 06:29:31 INFO DAGScheduler: ResultStage 3 (head at cmd7.sc:1) finished in 0.208 s\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/06/10 06:29:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "22/06/10 06:29:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Job 2 finished: head at cmd7.sc:1, took 0.212176 s\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.32.9:41811 in memory (size: 6.2 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO SparkContext: Starting job: head at cmd7.sc:1\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Got job 3 (head at cmd7.sc:1) with 4 output partitions\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Final stage: ResultStage 4 (head at cmd7.sc:1)\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Missing parents: List()\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at head at cmd7.sc:1), which has no missing parents\n",
      "22/06/10 06:29:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 20.3 KiB, free 1111.8 MiB)\n",
      "22/06/10 06:29:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 1111.7 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ecf4d78a32fa:36531 (size: 7.3 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200\n",
      "22/06/10 06:29:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at head at cmd7.sc:1) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "22/06/10 06:29:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 4 tasks\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 192.168.32.9, executor 0, partition 1, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, 192.168.32.8, executor 1, partition 2, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.32.9:41811 (size: 7.3 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.32.8:37127 (size: 7.3 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 6, 192.168.32.9, executor 0, partition 3, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 40 ms on 192.168.32.9 (executor 0) (1/4)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 7, 192.168.32.9, executor 0, partition 4, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 6) in 24 ms on 192.168.32.9 (executor 0) (2/4)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 73 ms on 192.168.32.8 (executor 1) (3/4)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 7) in 26 ms on 192.168.32.9 (executor 0) (4/4)\n",
      "22/06/10 06:29:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "22/06/10 06:29:32 INFO DAGScheduler: ResultStage 4 (head at cmd7.sc:1) finished in 0.107 s\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/06/10 06:29:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Job 3 finished: head at cmd7.sc:1, took 0.111639 s\n",
      "22/06/10 06:29:32 INFO SparkContext: Starting job: head at cmd7.sc:1\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Got job 4 (head at cmd7.sc:1) with 8 output partitions\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Final stage: ResultStage 5 (head at cmd7.sc:1)\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Missing parents: List()\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at head at cmd7.sc:1), which has no missing parents\n",
      "22/06/10 06:29:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 20.3 KiB, free 1111.7 MiB)\n",
      "22/06/10 06:29:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 1111.7 MiB)\n",
      "22/06/10 06:29:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ecf4d78a32fa:36531 (size: 7.3 KiB, free: 1111.8 MiB)\n",
      "22/06/10 06:29:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at head at cmd7.sc:1) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12))\n",
      "22/06/10 06:29:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 8 tasks\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 8, 192.168.32.9, executor 0, partition 5, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 9, 192.168.32.8, executor 1, partition 6, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.32.9:41811 (size: 7.3 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.32.8:37127 (size: 7.3 KiB, free: 93.3 MiB)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 10, 192.168.32.9, executor 0, partition 7, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 8) in 42 ms on 192.168.32.9 (executor 0) (1/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 11, 192.168.32.8, executor 1, partition 8, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 9) in 47 ms on 192.168.32.8 (executor 1) (2/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 12, 192.168.32.9, executor 0, partition 9, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 10) in 17 ms on 192.168.32.9 (executor 0) (3/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 13, 192.168.32.8, executor 1, partition 10, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 11) in 25 ms on 192.168.32.8 (executor 1) (4/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 14, 192.168.32.9, executor 0, partition 11, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 12) in 31 ms on 192.168.32.9 (executor 0) (5/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 15, 192.168.32.8, executor 1, partition 12, PROCESS_LOCAL, 7219 bytes)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 13) in 32 ms on 192.168.32.8 (executor 1) (6/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 14) in 21 ms on 192.168.32.9 (executor 0) (7/8)\n",
      "22/06/10 06:29:32 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 15) in 17 ms on 192.168.32.8 (executor 1) (8/8)\n",
      "22/06/10 06:29:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "22/06/10 06:29:32 INFO DAGScheduler: ResultStage 5 (head at cmd7.sc:1) finished in 0.128 s\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "22/06/10 06:29:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "22/06/10 06:29:32 INFO DAGScheduler: Job 4 finished: head at cmd7.sc:1, took 0.131831 s\n",
      "22/06/10 06:29:32 INFO CodeGenerator: Code generated in 6.069917 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres7\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mRow\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  [101,LADSQO,JKUESHADGZ],\n",
       "  [102,NWTCGE,WLWDLZKLNB],\n",
       "  [103,NSKRPV,OTHNDSBFER],\n",
       "  [104,IKPEYI,MMMENRIFZZ],\n",
       "  [105,QZWZLI,LPWCYBCYCK],\n",
       "  [106,EKHMVX,IYWKAUNLLY],\n",
       "  [107,ZKZXTY,TEZORKZQKG],\n",
       "  [108,ZTXXMC,WAUGAKRHDF],\n",
       "  [109,MYEOUF,IBGSTNWYYM],\n",
       "  [110,QEHWNI,DGCQCAPOTS],\n",
       "  [111,GIQPLW,RCYSRNLJOU],\n",
       "  [112,KHHGYJ,FRBSDKHXWQ],\n",
       "  [113,ONJXTA,ZMDJUAGKGZ],\n",
       "  [114,AWUAVH,EFBFLMLLLI],\n",
       "  [115,RZCYDH,ZISMUEXDGE],\n",
       "  [116,JKGQKO,JWJNTMUYFV],\n",
       "  [117,SEZHNV,QBPCVNIROJ],\n",
       "  [118,YUWULX,JOTWXLLHZF],\n",
       "  [119,IMKGWZ,ZTXLEEKKXZ],\n",
       "  [120,OUCOUV,LFAPPKNPQO],\n",
       "  [121,KWTFHZ,GXOQKDHZFM],\n",
       "  [122,KOZJVW,YLGBTFHGFZ],\n",
       "  [123,WUKSSW,YUPECVKBIX],\n",
       "  [124,KDNGCI,VGKRRMZORP],\n",
       "  [125,JVCRQJ,CIAOIPFXDY],\n",
       "  [126,MFLVHT,WVBLBZPASA],\n",
       "  [127,ARPTOL,VZMUPMMPQK],\n",
       "  [128,TDZEYZ,RTOEGDVRWQ],\n",
       "  [129,RSPQKJ,EOPIJGFAMG],\n",
       "  [130,YRUHWI,XESDJSQQWJ],\n",
       "  [131,DILMFQ,EJAXZQTJMJ],\n",
       "  [132,WYWMCG,MZFCTOPDXZ],\n",
       "  [133,WXDCKC,IMWXCZUBLG],\n",
       "  [134,UJRXSE,TPHSJIEQVB],\n",
       "  [135,ZSHELX,LEHTIXPJDO],\n",
       "  [136,GHODSS,LMAICKLQBU],\n",
       "  [137,ZGMRRZ,RZBCLRDFZM],\n",
       "  [138,XUSWLR,YODPRJPEMA],\n",
       "..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec1395-bb7b-4e22-a5b3-d1927b748a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12.10",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
